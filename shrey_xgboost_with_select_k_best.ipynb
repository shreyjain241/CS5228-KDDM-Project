{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    def __init__ (self):\n",
    "        self.start_time = time.time()\n",
    "        self.end_time = 0.0\n",
    "        self.duration = 0.0\n",
    "    def stop_timer(self):\n",
    "        self.end_time = time.time()\n",
    "        self.duration = self.end_time - self.start_time\n",
    "    def get_duration(self):\n",
    "        self.stop_timer()\n",
    "        return self.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_processed.csv')\n",
    "test_data = pd.read_csv('data/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train_data[['publisher','processed_titles','processed_texts', 'url_status']].copy()\n",
    "y_train_final = train_data['category'].as_matrix()\n",
    "X_test = test_data[['publisher','processed_titles','processed_texts', 'url_status']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer = TfidfVectorizer(strip_accents='unicode')\n",
    "text_vectorizer = TfidfVectorizer(strip_accents='unicode')\n",
    "label_encoder = LabelEncoder()\n",
    "url_status_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "publisher_encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publisher</th>\n",
       "      <th>processed_titles</th>\n",
       "      <th>processed_texts</th>\n",
       "      <th>url_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>forex pound drop one month low euro</td>\n",
       "      <td>forex pound drop one month low euro nasdaq com...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fox Business</td>\n",
       "      <td>hertz exit equip rental busi 2 5b spinoff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resource Investor</td>\n",
       "      <td>gold etf inflow return</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGR</td>\n",
       "      <td>hacker call mt gox ceo liar say still control ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forbes</td>\n",
       "      <td>gold climb to near 6 month high on concern abo...</td>\n",
       "      <td>gold climb to near 6 month high on concern abo...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           publisher                                   processed_titles  \\\n",
       "0             NASDAQ                forex pound drop one month low euro   \n",
       "1       Fox Business          hertz exit equip rental busi 2 5b spinoff   \n",
       "2  Resource Investor                             gold etf inflow return   \n",
       "3                BGR  hacker call mt gox ceo liar say still control ...   \n",
       "4             Forbes  gold climb to near 6 month high on concern abo...   \n",
       "\n",
       "                                     processed_texts  url_status  \n",
       "0  forex pound drop one month low euro nasdaq com...         200  \n",
       "1                                                NaN         404  \n",
       "2                                                NaN         404  \n",
       "3                                                NaN         404  \n",
       "4  gold climb to near 6 month high on concern abo...         200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = pd.concat([X_train.copy(),X_test.copy()])\n",
    "title_vectorizer.fit(X_all['processed_titles'])\n",
    "text_vectorizer.fit(X_all['processed_titles'])\n",
    "url_status_encoder.fit(X_all['url_status'].values.reshape(-1, 1))\n",
    "publisher_encoder.fit(label_encoder.fit_transform(X_all['publisher']).reshape(-1, 1))\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_title = title_vectorizer.transform(X_train['processed_titles']).todense()\n",
    "X_train_text = text_vectorizer.transform(X_train['processed_texts'].fillna(\"\")).todense()\n",
    "X_train_publisher = label_encoder.transform(X_train['publisher'])\n",
    "X_train_publisher = publisher_encoder.transform(X_train_publisher.reshape(-1, 1)).todense()\n",
    "X_train_url_status = url_status_encoder.transform(X_train['url_status'].values.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_title = title_vectorizer.transform(X_test['processed_titles']).todense()\n",
    "X_test_text = text_vectorizer.transform(X_test['processed_texts'].fillna(\"\")).todense()\n",
    "X_test_publisher = label_encoder.transform(X_test['publisher'])\n",
    "X_test_publisher = publisher_encoder.transform(X_test_publisher.reshape(-1, 1)).todense()\n",
    "X_test_url_status = url_status_encoder.transform(X_test['url_status'].values.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.concatenate([X_train_publisher, X_train_title, X_train_text, X_train_url_status], axis=1)\n",
    "X_test_final = np.concatenate([X_test_publisher, X_test_title, X_test_text, X_test_url_status], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectKBest(score_func=chi2,k=5000)\n",
    "X_train_final = feature_selector.fit_transform(X_train_final,y_train_final)\n",
    "X_test_final = feature_selector.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=5000)\n",
    "#pca.fit(np.concatenate([X_train_final,X_test_final], axis=0))\n",
    "#X_train_final = pca.transform(X_train_final)\n",
    "#X_test_final = pca.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.238717\tvalidation_1-merror:0.394824\n",
      "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-merror hasn't improved in 20 rounds.\n",
      "[1]\tvalidation_0-merror:0.230531\tvalidation_1-merror:0.380889\n",
      "[2]\tvalidation_0-merror:0.220575\tvalidation_1-merror:0.378898\n",
      "[3]\tvalidation_0-merror:0.213938\tvalidation_1-merror:0.370272\n",
      "[4]\tvalidation_0-merror:0.213496\tvalidation_1-merror:0.370272\n",
      "[5]\tvalidation_0-merror:0.205752\tvalidation_1-merror:0.3643\n",
      "[6]\tvalidation_0-merror:0.199115\tvalidation_1-merror:0.366954\n",
      "[7]\tvalidation_0-merror:0.190708\tvalidation_1-merror:0.360319\n",
      "[8]\tvalidation_0-merror:0.182965\tvalidation_1-merror:0.357664\n",
      "[9]\tvalidation_0-merror:0.18031\tvalidation_1-merror:0.35501\n",
      "[10]\tvalidation_0-merror:0.171018\tvalidation_1-merror:0.347711\n",
      "[11]\tvalidation_0-merror:0.162389\tvalidation_1-merror:0.353683\n",
      "[12]\tvalidation_0-merror:0.159513\tvalidation_1-merror:0.353683\n",
      "[13]\tvalidation_0-merror:0.154867\tvalidation_1-merror:0.351692\n",
      "[14]\tvalidation_0-merror:0.147788\tvalidation_1-merror:0.348374\n",
      "[15]\tvalidation_0-merror:0.14646\tvalidation_1-merror:0.346384\n",
      "[16]\tvalidation_0-merror:0.142699\tvalidation_1-merror:0.34572\n",
      "[17]\tvalidation_0-merror:0.136726\tvalidation_1-merror:0.343729\n",
      "[18]\tvalidation_0-merror:0.132522\tvalidation_1-merror:0.343066\n",
      "[19]\tvalidation_0-merror:0.130088\tvalidation_1-merror:0.344393\n",
      "[20]\tvalidation_0-merror:0.126549\tvalidation_1-merror:0.343066\n",
      "[21]\tvalidation_0-merror:0.124779\tvalidation_1-merror:0.343729\n",
      "[22]\tvalidation_0-merror:0.123009\tvalidation_1-merror:0.343729\n",
      "[23]\tvalidation_0-merror:0.120796\tvalidation_1-merror:0.342402\n",
      "[24]\tvalidation_0-merror:0.116372\tvalidation_1-merror:0.344393\n",
      "[25]\tvalidation_0-merror:0.113053\tvalidation_1-merror:0.342402\n",
      "[26]\tvalidation_0-merror:0.111062\tvalidation_1-merror:0.342402\n",
      "[27]\tvalidation_0-merror:0.108186\tvalidation_1-merror:0.344393\n",
      "[28]\tvalidation_0-merror:0.105752\tvalidation_1-merror:0.344393\n",
      "[29]\tvalidation_0-merror:0.104204\tvalidation_1-merror:0.343729\n",
      "[30]\tvalidation_0-merror:0.100664\tvalidation_1-merror:0.341075\n",
      "[31]\tvalidation_0-merror:0.099558\tvalidation_1-merror:0.340411\n",
      "[32]\tvalidation_0-merror:0.095796\tvalidation_1-merror:0.337094\n",
      "[33]\tvalidation_0-merror:0.093805\tvalidation_1-merror:0.338421\n",
      "[34]\tvalidation_0-merror:0.091814\tvalidation_1-merror:0.338421\n",
      "[35]\tvalidation_0-merror:0.090929\tvalidation_1-merror:0.337094\n",
      "[36]\tvalidation_0-merror:0.087389\tvalidation_1-merror:0.339084\n",
      "[37]\tvalidation_0-merror:0.085841\tvalidation_1-merror:0.339748\n",
      "[38]\tvalidation_0-merror:0.084292\tvalidation_1-merror:0.339748\n",
      "[39]\tvalidation_0-merror:0.082965\tvalidation_1-merror:0.338421\n",
      "[40]\tvalidation_0-merror:0.081637\tvalidation_1-merror:0.337757\n",
      "[41]\tvalidation_0-merror:0.079204\tvalidation_1-merror:0.337094\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "model = XGBClassifier(max_depth=20, silent=True, objective='multi:softmax', num_class=5, learning_rate=0.1, n_estimators=500)\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_cv, y_cv)], verbose=True, early_stopping_rounds=20)\n",
    "print (\"Training took {:.2f} seconds\". format(timer.get_duration()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_cv)\n",
    "accuracy = accuracy_score(y_cv, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_final)\n",
    "submission = pd.DataFrame(test_data['article_id'])\n",
    "submission['category'] = y_pred\n",
    "submission.to_csv('results/shrey_xgboost.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
